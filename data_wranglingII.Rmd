---
title: "data_wranglingII"
author: "Stephen Lewandowski"
date: "October 9, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)


  library(tidyverse)
  library(ggridges)
  library(patchwork)   # devtools::install_github("thomasp85/patchwork")
  library(rnoaa)

theme_set(theme_bw() + theme(legend.position = "bottom"))
```

## Data Wrangling II

This section will cover ways of getting data from the web, and take a closer look at strings and factors.

Load and view the data.

```{r}

library(p8105.datasets)
data(nyc_airbnb)
nyc_airbnb %>% View
```

Rename / clean some things

```{r}
nyc_airbnb <-
  nyc_airbnb %>%
  mutate(stars = review_scores_location / 2) %>% 
  rename(boro = neighbourhood_group)
  

```

```{r}
nyc_airbnb %>% 
  count(boro)

nyc_airbnb %>% 
  count(boro, neighbourhood) %>% View

```


## Some questions
* Does rating vary by neighborhood, room type, or both?
* How is price related to other variables?
* Where are rentals located?

* Mot expensive area? Least expensive?
* Most unfilled days?
* Highest density of listings?
* What are host characteristics? How many listings?



## Stars and Price

Histograms
```{r}
nyc_airbnb %>% 
  ggplot(aes(x = stars)) +
  geom_histogram()

nyc_airbnb %>% 
  filter(price < 500) %>% 
  ggplot(aes(x = price)) +
  geom_histogram()




```

Scatter plot

```{r}
nyc_airbnb %>% 
ggplot(aes(x = price, y = stars)) + 
  geom_point(aes(alpha = .5)) +
  geom_smooth(se = TRUE, method = "loess")
```



## Where are rentals located?

```{r}
nyc_airbnb %>% 
  filter(boro == "Manhattan") %>% 
  filter(price < 500) %>% 
  ggplot(aes(x = longitude, y = latitude, color = price)) + 
  geom_point(alpha = 0.2) +
  facet_grid(~room_type) +
  viridis::scale_color_viridis()
```


## Start of Data Wrangling II

## Reading data from the web

Load packages:

```{r}
library(rvest)
library(httr)
```

Load data from web:

```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

drug_use_xml = read_html(url)

drug_use_xml
```


Get the tables from the html:

```{r}

drug_use_xml %>%
  html_nodes(css = "table") %>% 
  .[[1]] %>%
  html_table() %>% 
  slice(-1) %>% 
  as_tibble()

```

### Cost of Living
Scrape NYC cost of living data:


```{r}

url_ny_cost = "https://www.bestplaces.net/cost_of_living/city/new_york/new_york"
nyc_cost = read_html(url_ny_cost) %>%
  html_nodes(css = "table") %>%
    .[[1]] %>%
  html_table(header = TRUE)

nyc_cost

```






