---
title: "data_wranglingII"
author: "Stephen Lewandowski"
date: "October 9, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)


  library(tidyverse)
  library(ggridges)
  library(patchwork)   # devtools::install_github("thomasp85/patchwork")
  library(rnoaa)

theme_set(theme_bw() + theme(legend.position = "bottom"))
```

## Data Wrangling II

This section will cover ways of getting data from the web, and take a closer look at strings and factors.

Load and view the data.

```{r}

library(p8105.datasets)
data(nyc_airbnb)
nyc_airbnb %>% View
```

Rename / clean some things

```{r}
nyc_airbnb <-
  nyc_airbnb %>%
  mutate(stars = review_scores_location / 2) %>% 
  rename(boro = neighbourhood_group)
  

```

```{r}
nyc_airbnb %>% 
  count(boro)

nyc_airbnb %>% 
  count(boro, neighbourhood) %>% View

```


## Some questions
* Does rating vary by neighborhood, room type, or both?
* How is price related to other variables?
* Where are rentals located?

* Mot expensive area? Least expensive?
* Most unfilled days?
* Highest density of listings?
* What are host characteristics? How many listings?



## Stars and Price

Histograms
```{r}
nyc_airbnb %>% 
  ggplot(aes(x = stars)) +
  geom_histogram()

nyc_airbnb %>% 
  filter(price < 500) %>% 
  ggplot(aes(x = price)) +
  geom_histogram()




```

Scatter plot

```{r}
nyc_airbnb %>% 
ggplot(aes(x = price, y = stars)) + 
  geom_point(aes(alpha = .5)) +
  geom_smooth(se = TRUE, method = "loess")
```



## Where are rentals located?

```{r}
nyc_airbnb %>% 
  filter(boro == "Manhattan") %>% 
  filter(price < 500) %>% 
  ggplot(aes(x = longitude, y = latitude, color = price)) + 
  geom_point(alpha = 0.2) +
  facet_grid(~room_type) +
  viridis::scale_color_viridis()
```


## Start of Data Wrangling II

## Reading data from the web

Load packages:

```{r}
library(rvest)
library(httr)
```

Load data from web:

```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

drug_use_xml = read_html(url)

drug_use_xml
```


Get the tables from the html:

```{r}

drug_use_xml %>%
  html_nodes(css = "table") %>% 
  .[[1]] %>%
  html_table() %>% 
  slice(-1) %>% 
  as_tibble()

```

### Cost of Living
Scrape NYC cost of living data:


```{r}

url_ny_cost = "https://www.bestplaces.net/cost_of_living/city/new_york/new_york"
nyc_cost = read_html(url_ny_cost) %>%
  html_nodes(css = "table") %>%
    .[[1]] %>%
  html_table(header = TRUE)

nyc_cost

```


### Harry Potter

Get html:
```{r}
hpsaga_html = read_html("https://www.imdb.com/list/ls000630791/")
```

Use CSL Selector

```{r}
title_vec = hpsaga_html %>%
  html_nodes(".lister-item-header a") %>%
  html_text()

gross_rev_vec = hpsaga_html %>%
  html_nodes(".text-small:nth-child(7) span:nth-child(5)") %>%
  html_text()

runtime_vec = hpsaga_html %>%
  html_nodes(".runtime") %>%
  html_text()

hpsaga_df = tibble(
  title = title_vec,
  rev = gross_rev_vec,
  runtime = runtime_vec
)

hpsaga_df
```

### Napoleon Dynamite

```{r}
url_napolean = "https://www.amazon.com/product-reviews/B00005JNBQ/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1"

dynamite_html = read_html(url_napolean)

review_titles = dynamite_html %>%
  html_nodes("#cm_cr-review_list .review-title") %>%
  html_text()

review_stars = dynamite_html %>%
  html_nodes("#cm_cr-review_list .review-rating") %>%
  html_text()

review_text = dynamite_html %>%
    html_nodes(".review-data:nth-child(4)") %>%
    html_text()

reviews = tibble(
  title = review_titles,
  stars = review_stars,
  text = review_text
)

reviews
```


## Using an API

Get the NYC water data.

```{r}
nyc_water = GET("https://data.cityofnewyork.us/resource/waf7-5gvc.csv") %>% 
  content("parsed")

nyc_water

```


As JSON:

```{r}
nyc_water = GET("https://data.cityofnewyork.us/resource/waf7-5gvc.json") %>% 
  content("text") %>%
  jsonlite::fromJSON() %>%
  as_tibble()

nyc_water
```

